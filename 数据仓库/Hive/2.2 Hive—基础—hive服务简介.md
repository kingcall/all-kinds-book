[TOC]

## Hive 服务详解



### 元数据服务

按官网的介绍，不管是使用Hive CLI、客户端还是HWI访问Hive，都需要首先启动Hive 元数据服务，否则无法访问Hive数据库。否则会报异常

```
15/01/09 16:37:58 INFO hive.metastore: Trying to connect to metastore with URI thrift://172.17.0.1:9083  
15/01/09 16:37:58 WARN hive.metastore: Failed to connect to the MetaStore Server...  
15/01/09 16:37:58 INFO hive.metastore: Waiting 1 seconds before next connection attempt.  
```



1. hive --service metastore  



### Hive Web Interface（hwi)

### beeline

 beeline 是 hive 提供的一个**新的命令行工具**，**基于SQLLine CLI的JDBC客户端**，beeline 要与HiveServer2配合使用，支持嵌入模式和远程模式两种，也即既可以像hive client一样访问本机的hive服务，也可以通过指定ip和端口远程访问某个hive服务。hive 官网是推荐使用beeline，它还提供了更为友好的显示方式（类似MySQL client）

a、要使用 beeline ，先把 hiveserver2 启动起来，默认端口为10000

```bash
# 启动 hiveserver2
$ hiveserver2
```

b、使用beeline

```bash
# 1、指定要连接的hiveserver2的主机、端口
beeline -u jdbc:hive2://hd1:10000
# 2、如果是本机的hiveserver2，则可省略主机、端口
```

### hiveserver2

### HCatalog

 HCatalog是Hadoop的元数据和数据表的管理系统，它是基于Hive的元数据层，通过类SQL的语言展现Hadoop数据的关联关系，支持Hive、Pig、MapReduce等共享数据和元数据，使用户在编写应用程序时无需关心数据是怎么存储、存在哪里，避免用户因schema和存储格式的改变而受到影响。HCatalog的这种灵活性，使得在不影响到使用者的应用程序读取数据的情况下，数据产生者可以在数据中增加新列。在不影响生产者或使用者的情况下，管理员可以迁移数据或是改变数据的存储格式

![image-20201221145711007](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/image-20201221145711007.png)

 从上图可看出，HCatalog低层支持多种文件格式的数据存储方法，上层支持Pig、MapReduce、Hive、Streaming等多种应用。

​    这样的好处在于，可以支持不同的工具集和系统能在一起使用，例如数据分析团队，一开始可能只使用一种工具（如Hive，Pig，Map Reduce），而随着数据分析工作的深入，需要多种工具相结合，如刚开始使用Hive进行分析查询的用户，后面还需要使用Pig为ETL过程处理或建立数据模型；刚开始使用Pig的用户发现，他们更想使用Hive进行分析查询。在这些情况下，通过HCatalog提供了元数据之间的共享，使用户更方便的在不同工具间切换操作，比如在 Map Reduce或Pig中载入数据并进行规范化，然后通过Hive进行分析，当这些工具都共享一个metastore时，各个工具的用户就能够即时访问其他工具创建的数据，而无需载入和传输的步骤，非常高效、方便。

  Apache Hive 对 **[HCatalog 有详细的介绍说明](https://cwiki.apache.org/confluence/display/Hive/HCatalog+UsingHCat)**。从 hive 0.11.0 版本之后，hive 安装包便提供了 hcatalog，也即安装hive后，里面就已经有了hcatalog了（**[官网说明](https://cwiki.apache.org/confluence/display/Hive/HCatalog+InstallHCat#HCatalogInstallHCat-HCatalogInstalledwithHive)**）。接下来将介绍如何配置使用 HCatalog



### **WebHCat**

WebHCat是为HCatalog提供REST API的服务，自hive 0.11.0 版本之后，hive 中也自带了 webhcat （**[官网介绍说明](https://cwiki.apache.org/confluence/display/Hive/WebHCat+InstallWebHCat)**），如下图，通过WebHCat，程序能够通过REST的API很安全的链接和操作HCatalog提供的服务，方便Hive、Pig、MapReduce等应用使用。（类似于通过WebHDFS以web的方式来操作HDFS）

![img](https://static.oschina.net/uploads/space/2017/0628/090624_rclF_876354.png)

使用以下命令启动 webhcat，默认的web端口为50111（须先启动 hcat_srever.sh start）

```bash
webhcat_server.sh start &
```

（1）在浏览器输入 http://172.17.0.1:50111/templeton/v1/status 可查看 hcatalog 的状态，