[TOC]

## Hive 服务详解



### 元数据服务

按官网的介绍，不管是使用Hive CLI、客户端还是HWI访问Hive，都需要首先启动Hive 元数据服务，否则无法访问Hive数据库。否则会报异常

```
2020-12-22 21:36:12,203 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(441)) - Trying to connect to metastore with URI thrift://localhost:9083
2020-12-22 21:36:12,224 WARN  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(526)) - Failed to connect to the MetaStore Server...
2020-12-22 21:36:12,224 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(557)) - Waiting 1 seconds before next connection attempt.
2020-12-22 21:36:13,227 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(441)) - Trying to connect to metastore with URI thrift://localhost:9083
2020-12-22 21:36:13,228 WARN  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(526)) - Failed to connect to the MetaStore Server...
2020-12-22 21:36:13,228 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(557)) - Waiting 1 seconds before next connection attempt.
2020-12-22 21:36:14,229 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(441)) - Trying to connect to metastore with URI thrift://localhost:9083
2020-12-22 21:36:14,230 WARN  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(526)) - Failed to connect to the MetaStore Server...
2020-12-22 21:36:14,230 INFO  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metastore.HiveMetaStoreClient (HiveMetaStoreClient.java:open(557)) - Waiting 1 seconds before next connection attempt.
2020-12-22 21:36:15,235 WARN  [1667ccc9-b01a-4f12-af7f-6ad7a563f46e main] metadata.Hive (Hive.java:registerAllFunctionsOnce(277)) - Failed to register all functions.
java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
	at org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:86)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4299)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4367)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4347)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:4603)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:291)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:274)
	at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:435)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:375)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:355)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:331)
	at org.apache.hadoop.hive.ql.metadata.HiveMaterializedViewsRegistry.init(HiveMaterializedViewsRegistry.java:133)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:755)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.lang.reflect.InvocationTargetException
```

这里我们可以看到在几次尝试之后，终于还是报错了

这里我们可以尝试将这个服务启动然后进行连接hive	 `nohup hive --service metastore &`

```
2020-12-22 21:39:06,432 INFO  [38c08100-6fd8-499d-9c8e-578d890ab8e4 main] CliDriver (SessionState.java:printInfo(1227)) - Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2020-12-22 21:39:06,438 INFO  [pool-7-thread-1] session.SessionState (SessionState.java:createPath(790)) - Created HDFS directory: /tmp/hive/liuwenqiang/ac02bd92-da32-4a9b-a286-580b0f4e1e1b
2020-12-22 21:39:06,443 INFO  [pool-7-thread-1] session.SessionState (SessionState.java:createPath(790)) - Created local directory: /tmp/hive/local/ac02bd92-da32-4a9b-a286-580b0f4e1e1b
2020-12-22 21:39:06,445 INFO  [pool-7-thread-1] session.SessionState (SessionState.java:createPath(790)) - Created HDFS directory: /tmp/hive/liuwenqiang/ac02bd92-da32-4a9b-a286-580b0f4e1e1b/_tmp_space.db
2020-12-22 21:39:06,491 INFO  [pool-7-thread-1] metadata.HiveMaterializedViewsRegistry (HiveMaterializedViewsRegistry.java:run(171)) - Materialized views registry has been initialized
```

这个时候你就看不到不错了，hive 命令行就可以成功连上了

### Hive Web Interface（hwi)

hive 的web 界面，用的很少

### beeline

 beeline 是 hive 提供的一个**新的命令行工具**，**基于SQLLine CLI的JDBC客户端**，beeline 要与HiveServer2配合使用，支持嵌入模式和远程模式两种，也即既可以像hive client一样访问本机的hive服务，也可以通过指定ip和端口远程访问某个hive服务。hive 官网是推荐使用beeline，它还提供了更为友好的显示方式（类似MySQL client）

a、要使用 beeline ，先把 hiveserver2 启动起来，默认端口为10000

```bash
# 启动 hiveserver2
$ hiveserver2
```

b、使用beeline

```bash
# 1、指定要连接的hiveserver2的主机、端口
beeline -u jdbc:hive2://hd1:10000
# 2、如果是本机的hiveserver2，则可省略主机、端口
```

### hiveserver2

### HCatalog

 HCatalog是Hadoop的元数据和数据表的管理系统，它是基于Hive的元数据层，通过类SQL的语言展现Hadoop数据的关联关系，支持Hive、Pig、MapReduce等共享数据和元数据，使用户在编写应用程序时无需关心数据是怎么存储、存在哪里，避免用户因schema和存储格式的改变而受到影响。HCatalog的这种灵活性，使得在不影响到使用者的应用程序读取数据的情况下，数据产生者可以在数据中增加新列。在不影响生产者或使用者的情况下，管理员可以迁移数据或是改变数据的存储格式

![image-20201221145711007](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/image-20201221145711007.png)

 从上图可看出，HCatalog低层支持多种文件格式的数据存储方法，上层支持Pig、MapReduce、Hive、Streaming等多种应用。

​    这样的好处在于，可以支持不同的工具集和系统能在一起使用，例如数据分析团队，一开始可能只使用一种工具（如Hive，Pig，Map Reduce），而随着数据分析工作的深入，需要多种工具相结合，如刚开始使用Hive进行分析查询的用户，后面还需要使用Pig为ETL过程处理或建立数据模型；刚开始使用Pig的用户发现，他们更想使用Hive进行分析查询。在这些情况下，通过HCatalog提供了元数据之间的共享，使用户更方便的在不同工具间切换操作，比如在 Map Reduce或Pig中载入数据并进行规范化，然后通过Hive进行分析，当这些工具都共享一个metastore时，各个工具的用户就能够即时访问其他工具创建的数据，而无需载入和传输的步骤，非常高效、方便。

  Apache Hive 对 **[HCatalog 有详细的介绍说明](https://cwiki.apache.org/confluence/display/Hive/HCatalog+UsingHCat)**。从 hive 0.11.0 版本之后，hive 安装包便提供了 hcatalog，也即安装hive后，里面就已经有了hcatalog了（**[官网说明](https://cwiki.apache.org/confluence/display/Hive/HCatalog+InstallHCat#HCatalogInstallHCat-HCatalogInstalledwithHive)**）。接下来将介绍如何配置使用 HCatalog



### **WebHCat**

WebHCat是为HCatalog提供REST API的服务，自hive 0.11.0 版本之后，hive 中也自带了 webhcat （**[官网介绍说明](https://cwiki.apache.org/confluence/display/Hive/WebHCat+InstallWebHCat)**），如下图，通过WebHCat，程序能够通过REST的API很安全的链接和操作HCatalog提供的服务，方便Hive、Pig、MapReduce等应用使用。（类似于通过WebHDFS以web的方式来操作HDFS）

![img](https://static.oschina.net/uploads/space/2017/0628/090624_rclF_876354.png)

使用以下命令启动 webhcat，默认的web端口为50111（须先启动 hcat_srever.sh start）

```bash
webhcat_server.sh start &
```

（1）在浏览器输入 http://172.17.0.1:50111/templeton/v1/status 可查看 hcatalog 的状态，