# MapReduce 数据本地化

数据本地化是指把计算移动到数据所在节点上进行执行的过程，也就是通常所说的 “移动计算而不是移动数据”。移动计算比移动数据具有更大的优势，它可以降低网络开销，增加系统的整体吞吐量。

## 数据本地化的概念

让我们来理解一下数据本地化的概念，以及什么 MapReduce 数据本地化。

Hadoop 主要的缺点是跨交换网络传输巨量的数据。为了克服这个缺点，Hadoop 提出了数据本地化概念。数据本地化的指的是把计算移动到尽可能离数据近的地方执行，因为移动计算比移动巨量数据要更高效，它可以降低网络开销，增加系统的整体吞吐量。

在 Hadoop 中，数据集是存储在 HDFS 的。而数据集会被切割成很多块，这些块会被存储在 Hadoop 集群的不同节点。在执行 MapReduce 作业的时候，NameNode 把这些 MapReduce 程序的代码发送给与该程序代码将要处理的数据所在 的 datanode 上。这个过程可以结合下面的图来理解。

![mapreduce 数据本地化 ](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/data-locality-hadoop-mapreduce-20210112085712571.gif)

## MapReduce 数据本地化的要求

为了达到数据本地化的所有优势，系统架构需要满足下面的条件：

- 首先，集群应该具备合理的拓扑结构。Hadoop 代码必须具有读取数据位置的能力。
- 其次，Hadoop 必须对集群内执行任务的节点的拓扑结构具有感知能力。而且 Hadoop 必须知道数据存储的具体位置。

## Hadoop 数据本地化分类

数据本地化有下面几种不同情况：

### Data Local（数据和计算在同一个节点）

数据和计算代码在同一个节点内，在这种情况下，计算和数据距离非常近，计算操作数据不需要经过网络，这是最优的情况。

### Intra-Rack（数据和计算在同一个机架内）

由于资源有限，mapper 不可能总是在同一个节点执行。这种情况下，mapper 在同一个机架的不同节点运行是相对比较好的。

### Inter-Rack（数据和计算在不同机架）

有时由于资源限制，不能在同一个机架内的不同节点执行 mapper，所以只能在不同机架的不同节点执行 mapper。这种情况相对来说是性能最差的情况。

## Hadoop 数据本地化优化

虽然数据本地化是 Hadoop MapReduce 框架的主要优势，因为 map 代码是在数据所在的节点执行的，但在实践中由于其他各种原因，比如推测执行，异构集群，数据本地化并非总是正确的。在超大集群各种挑战变得更加普遍，因为大集群的数据节点更多，数据量更大，数据本地化的情况会更少。在大集群里面，某些节点是比其他节点更新且跑的更快，造成数据计算比例失衡，因此，大集群往往不是完全均匀的。在发生推测计算时，即使数据不是本地的，但它可以利用集群的强大的计算能力。非本地数据的处理给网络带来比较大的压力，这在可伸缩性方面会出现问题。因此网络就成为瓶颈了。

我们可以通过检查哪些 job 存在数据本地化问题来改善数据本地化。解决问题比较复杂，包括数据布置和数据布局的修改，使用其他调度器或者通过简单修改 job 的 mapper 和 reducer 的数量。然后我们必须验证一个新的具有同样负载的计算是否具有更好的数据本地化比率。

## Hadoop 数据本地化的优势

MapReduce 的数据本地化有下面 2 个好处：

### 更快的执行

如果具备数据本地化，那么程序代码会被移动到数据所在的节点上运行，这可以让 Hadoop 运行的更快。因为程序代码相对数据量来说要小的多，而如果移动数据，由于数据的量比较大，在传输的实时这可能会成为网络的瓶颈。

### 高吞吐量

数据本地化可以增加系统整体吞吐量。