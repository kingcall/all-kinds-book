# HDFS 数据块

要把大文件存储在 HDFS上，HDFS 会把大文件分割成小块，即我们通常说的数据块（ block ），它是 Hadoop 分布式文件系统最小的存储单元，而且我们没办法决定指定块的存储节点地址，这些 Namenode 会替我们决定。数据块默认大小是 128MB，比操作系统里面的块概念要大很多（操作系统块大小是 4KB ），我们可以根据实际需求修改 HDFS 块大小。文件的所有数据块大小都是一样的，除了最后一个，它可能小于块大小或者刚好等于块大小。文件会被分割成若干个 128MB 的小数据块，再写入HDFS的。

![hdfs数据块](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/file_1570182985000_20191004175626041370.png)

假如需要把一个 518MB 的文本文件 Example.txt 存储到 HDFS，在块大小默认情况下，HDFS 将会创建 5 个数据块，前面4个数据块大小将是 128MB，最后一个是 6MB，而不是 128MB。这样会节省不少存储空间。

## HDFS 块大小为什么默认是 128MB

HDFS 存储的数据集一般比较大，数据量级一般是 TB 级别或者 PB 级别的。如果像 Linux 系统那样每个块只有 4KB。那么 HDFS 将会存储非常多的数据块，这将导致元数据暴增，NameNode 管理维护这些元数据将非常吃力。且很快会成为集群性能的瓶颈。另一方面，数据块的大小不能太大，不然文件系统处理数据延迟会更加严重。

## HDFS 数据块的优势

以下是 HDFS 数据块的优势：

### 方便管理

由于数据块的固定的，磁盘能够存储多少数据块很容易就可以计算出来。

### 存储大文件

HDFS 可以存储比单个磁盘容量还大的数据文件，因为文件会被划分成多个 HDFS 数据块，并存储在集群的多个Datanode 磁盘上。

### 容错性和高可用

数据块很容易在 Datanode 之间复制，以便达到数据的容错性和高可用性。

### 简单的 Datanode 存储机制

HDFS 数据块的概念简化了 Datanode 的数据存储方式。所有块的元数据都是在 Namenode 维护的。Datanode 不需要关心块的元数据，比如文件权限，存储位置等。