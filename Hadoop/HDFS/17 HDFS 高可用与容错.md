# HDFS 高可用与容错

![HDFS高可用配置](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/file_1570183592000_20191004180633293380-20210111224052603.png)

HDFS 是一个分布式文件系统，它会给文件创建副本并把副本分发到集群的节点上，因此，在读取数据的时候可以从多个节点上读取。这对数据的容错是非常有益的，在读取的时候，节点挂了，可以去其他节点读取相同的数据。HDFS 就是通过这种方式实现了数据的高可用和容错。

## HDFS 如何实现高可用

一个 HDFS 集群一般有很多 Datanode 节点，并且会定期给 Namenode 发送心跳信息，如果 Namenode 在规定时间内没接收到 Datanode 的心跳信息，那么它就会认为该 Datanode 发生故障了。接着它会检查节点上的存在的数据，并给其他 Datanode（ 这些 Datanode 存储了损坏节点的数据 ） 发送指令，创建数据的拷贝并存储到另外的 Datanode。因此，数据总是保持可用的。

从 HDFS 读取数据时，Namenode 会先检查哪些 Datanode 的数据是可用的，再把存储数据的 Datanode 地址列表返回。客户端不需要遍历集群的所有节点查找数据，只需根据 Namenode 提供的 Datanode 地址列表，直接从对应的 Datanode 读取数据即可。

## HDFS 数据容错

HDFS 容错指的是集群部分机器宕机了，集群依然可以正常提供服务的能力。HDFS 是具有很好的容错性的分布式存储系统，它利用复制技术实现数据容错能力，数据会被复制多份并存储在集群的不同节点。这样，集群中的某些机器宕机了，数据还可以从其他正常运行的机器获取。如果有一个机器宕机了，HDFS 会在其他可用的机器创建数据的副本，来保证该数据的副本数与集群的副本因子是一致的。
![HDFS数据容错机制](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/file_1570183681000_20191004180802482222-20210111224058147.png)

## HDFS 如何实现容错

HDFS 通过复制进程来保证容错机制。在文件写入 HDFS 时，HDFS 会首先把文件分割成块，并把这些数据块存储在集群不同机器上，然后在其他机器创建各个块的副本，默认情况下，HDFS 会在其他机器创建3个文件的副本。所以，HDFS 集群任意机器挂了，我们依然能从其他保存数据副本的机器上读取数据，由于这种独特的分布式存储特性，HDFS 给我们提供了更快的文件读写机制。