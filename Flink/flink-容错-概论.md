[toc]
# 容错
- Flink 实现容错主要靠强大的 CheckPoint 机制和 State 机制。
- Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份
- State 用来存储计算过程中的中间状态。

## 容错的必要条件
- 应用程序需要能够可靠地获取检查点
- 发生故障后，资源需要足以赶上输入数据流

## 有状态的计算
-  计算任务的结果不仅仅依赖于输入，还依赖于它的当前状态，其实大多数的计算都是有状态的计算
> 比如wordcount,给一些word,其计算它的count,这是一个很常见的业务场景。count做为输出，在计算的过程中要不断的把输入累加到count上去，那么count就是一个state

### 批计算的状态
- 在传统的批处理中，数据是划分为块分片去完成的，然后每一个Task去处理一个分片。当分片执行完成后，把输出聚合起来就是最终的结果。在这个过程当中，对于state的需求还是比较小的。

### 传统流计算缺少对于程序状态的有效支持
-  对于流计算而言，对State有非常高的要求，因为在流系统中输入是一个无限制的流，会运行很长一段时间，甚至运行几天或者几个月都不会停机。在这个过程当中，就需要将状态数据很好的管理起来。很不幸的是，在传统的流计算系统中，对状态管理支持并不是很完善。比如storm,没有任何程序状态的支持，一种可选的方案是storm+hbase这样的方式去实现，把这状态数据存放在Hbase中，计算的时候再次从Hbase读取状态数据，做更新在写入进去

![image-20210202100205988](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/image-20210202100205988.png)
#### 状态数据的存储和访问
#### 状态数据的备份和恢复；
#### 状态数据的划分和动态扩容；


## 容错   
- Flink提供了可以一致地恢复数据流应用状态的容错机制，该机制保证即使在错误发生后，反射回数据流记录的程序的状态操作最终仅执行一次。
- 容错机制持续地从分布式数据流图中取得快照。对于拥有少量状态的流式应用，这些快照是非常轻量级的，故它们可以在频繁获取时仍然不过多影响运行效率。
- 流式应用的状态将被存储在一个配置位置中（如一个master节点、HDFS中等）。
- 在程序失效时（不论源自硬件、网络、软件等），flink将会停止分布式数据流图，而后系统将会重启Operator并重置它们到最近成功的检查点。输入流将会被重置到状态快照的时间点。flink保证重启的并行数据流图中的所有已处理的记录都不会出现在检查点状态之前的部分中。
- Flink提供了不同的状态后台，用于指定状态的存储方式和位置。
 State可以位于Java堆上或堆外。根据您的状态后台，Flink还可以管理应用程序的状态，这意味着Flink处理内存管理（如果需要可能会溢出到磁盘）以允许应用程序保持非常大的状态。
- 每个任务通过发送描述分布式存储中状态位置的句柄来确认成功将状态写入JobManager。反过来，JobManager从所有任务中收集句柄并将它们捆绑到检查点对象中。
- 恢复的情况下，JobManager打开最新的检查点对象并将句柄发送回相应的任务，然后可以从分布式存储中恢复其状态。
使用分布式存储来存储状态有两个重要的优点。首先，存储是容错的，其次，分布式存储中的所有状态都可以被所有节点访问，并且可以容易地重新分配

## savepoint 和 checkpoint 对比
   - checkpoint 增量模型，每次数据量比较小，由程序在后台自行完成
   - savepoint 全量，需要用户手动触发，主要用于程序bug 修复,运行环境升级，A/B 测试。
   - Checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；Checkpoint 是作业 failover 的时候自动使用，不需要用户指定。
   - Savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。Savepoint 一般用于程序的版本更新（详见文档），Bug 修复，A/BTest 等场景，需要用户指定。

### 容错模型
##### Storm的Record acknowledgement模式
   - storm的fault tolerant是这样工作的：每一个被storm的operator处理的数据都会向其上一个operator发送一份应答消息，通知其已被下游处理。
   - storm的源operator保存了所有已发送的消息的每一个下游算子的应答消息，**当它收到来自sink的应答时**，它就知道该消息已经被完整处理，可以移除了。
   - 如果没有收到应答，storm就会重发该消息。显而易见，这是一种at least once的逻辑。
   - 另外，这种方式面临着严重的幂等性问题，例如对一个count算子，如果count的下游算子出错，source重发该消息，那么防止该消息被count两遍的逻辑需要程序员自己去实现。
   - 这样一种处理方式非常低效，吞吐量很低。

#### Spark streaming的micro batch模式
   - storm的实现方式就注定了与高吞吐量无缘。那么，为了提高吞吐量，把一批数据聚集在一起处理就是很自然的选择。Spark Streaming的实现就是基于这样的思路 
   - 通过控制每批计算数据的大小来控制延迟与吞吐量的制约，如果想要低延迟，就用小一点的batch，如果想要大吞吐量，就不得不忍受更高的延迟
   - 上游不用等待下游，但是当下游出错了上游要重新发送数据（重放）
   - 可以在每个batch中做到exactly-once，但是这种方式也有其弊端：
       - batch的方式使得一些需要跨batch的操作变得非常困难，例如session window；用户不得不自己想办法去实现相关逻辑。
       - batch模式很难做好背压。当一个batch因为种种原因处理慢了，那么下一个batch要么不得不容纳更多的新来数据，要么不得不堆积更多的batch，整个任务可能会被拖垮，这是一个非常致命的问题。
       - batch的方式基本意味着其延迟是有比较高的下限的，实时性上不好。

####  Google Cloud Dataflow的事务式模型、
   - 我们在传统数据库，如mysql中使用binlog来完成事务，这样的思路也可以被用在实现exactly-once模型中。
   - 例如，我们可以log下每个数据元素每一次被处理时的结果和当时所处的操作符的状态。这样，当我们需要fault tolerant时，我们只需要读一下log就可以了。
   - 这种模式规避了storm和spark所面临的问题，并且能够很好的实现exactly-once，唯一的弊端是：如何尽可能的减少log的成本？Flink给了我们答案。 

#### Flink 的实现
   - 实现exactly-once的关键是什么？是能够准确的知道和快速记录下来当前的operator的状态、当前正在处理的元素（以及正处在不同算子之间传递的元素）。

    如果上面这些可以做到，那么fault tolerant无非就是从持久化存储中读取上次记录的这些元信息，并且恢复到程序中。那么Flink是如何实现的呢？
   - Flink的分布式快照的核心是其轻量级异步分布式快照机制。为了实现这一机制，flink引入了一个概念，叫做Barrier。

    Barrier是一种标记，它被source产生并且插入到流数据中，被发送到下游节点。
    当下游节点处理到该barrier标志时，这就意味着在该barrier插入到流数据时，已经进入系统的数据在当前节点已经被处理完毕。
   - 每当一个barrier流过一个算子节点时，就说明了在该算子上，可以触发一次检查点，用以保存当前节点的状态和已经处理过的数据，这就是一份快照。
      （在这里可以联想一下micro-batch，把barrier想象成分割每个batch的逻辑，会好理解一点）这样的方式下，记录快照就像和前面提到的micro-batch一样容易。 
   - 与此同时，该算子会向下游发送该barrier。因为数据在算子之间是按顺序发送的，所以当下游节点收到该barrier时，也就意味着同样的一批数据在下游节点上也处理完毕，
      可以进行一次checkpoint，保存基于该节点的一份快照，快照完成后，会通知JobMananger自己完成了这个快照。这就是分布式快照的基本含义。
   - 当整个程序的最后一个算子sink都收到了这个barrier，也就意味着这个barrier和上个barrier之间所夹杂的这批元素已经全部落袋为安。
      这时，最后一个算子通知JobManager整个流程已经完成，而JobManager随后发出通知，要求所有算子删除本次快照内容，以完成清理。

## 离线任务的容错
- flink 1.9 以前是当批处理中有一个task失败的时候，就取消所有的task然后重启整个作业进行恢复，即就是所有的task都从头开始，所有的进度都会废弃
- flink 1.9 之后，会将中间结果保存下来，数据恢复的时候仅仅恢复失败的task